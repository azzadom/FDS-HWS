{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project:** Pathology Detection in Crop Plants\n",
    "\n",
    "Members:\n",
    "* Domenico Azzarito​\n",
    "* Guillermo Bajo Laborda​\n",
    "* Laura Alejandra Moreno​\n",
    "* Arian Gharehmohammadzadehghashghaei​\n",
    "* Michele Pezza\n",
    "\n",
    "\n",
    "*Fundamentals of Data Science | Sapienza University of Rome*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CNN\n",
    "\n",
    "In this step, the image data has been loaded, and also a normaliation, resizing and augmentation process has been implemented.\n",
    "\n",
    "The key libraries used were TensorFlow for image processing, Pandas for handling the CSV files, and also os library. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', 'healthy', 'multiple_diseases', 'rust', 'scab'], dtype='object')\n",
      "  image_id  healthy  multiple_diseases  rust  scab\n",
      "0  Train_0        0                  0     0     1\n",
      "1  Train_1        0                  1     0     0\n",
      "2  Train_2        1                  0     0     0\n",
      "3  Train_3        0                  0     1     0\n",
      "4  Train_4        1                  0     0     0\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "data_dir = 'images/'  \n",
    "sample_submission_csv = 'sample_submission.csv'\n",
    "test_csv = 'test.csv'\n",
    "train_csv = 'train.csv' \n",
    "train_df = pd.read_csv(train_csv)\n",
    "print(train_df.columns)\n",
    "train_df.columns = train_df.columns.str.strip()\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the encoded labels into arrays\n",
    "def con_process_labels(df):\n",
    "    labels = df[['healthy', 'multiple_diseases', 'rust', 'scab']].values\n",
    "    return labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decode function to load and preprocess the image file\n",
    "\n",
    "def decode_image(filename, label=None, image_size=(500, 500)):\n",
    "    filepath = tf.strings.join([data_dir, filename])  \n",
    "    bits = tf.io.read_file(filepath)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) \n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation to the images\n",
    "\n",
    "def data_augmentation(image, label=None):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Tensorflow dataset for testing\n",
    "\n",
    "def prepare_dataset(df, image_size=(500, 500), batch_size=32, augment=False, is_train=True):\n",
    "    file_paths = df['image_id'] + '.jpg'  \n",
    "    \n",
    "    if is_train:\n",
    "        labels = con_process_labels(df) \n",
    "        dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "        dataset = dataset.map(lambda x, y: decode_image(x, y, image_size))  \n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(file_paths)\n",
    "        dataset = dataset.map(lambda x: decode_image(x, label=None, image_size=image_size))\n",
    "    \n",
    "    if augment and is_train:\n",
    "        dataset = dataset.map(data_augmentation)  \n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)  \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Create train dataset\n",
    "train_dataset = prepare_dataset(train_df, image_size=image_size, augment=True, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(test_csv)\n",
    "test_df.columns = test_df.columns.str.strip()  # Clean the column names for test set\n",
    "test_dataset = prepare_dataset(test_df, image_size=(500, 500), augment=False, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: (32, 1365, 2048, 3)\n",
      "Label batch shape: (32, 4)\n"
     ]
    }
   ],
   "source": [
    "#Verification \n",
    "for image_batch, label_batch in train_dataset.take(1):\n",
    "    print(f\"Image batch shape: {image_batch.shape}\")\n",
    "    print(f\"Label batch shape: {label_batch.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
