{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project:** Pathology Detection in Crop Plants\n",
    "\n",
    "Members:\n",
    "* Domenico Azzarito​\n",
    "* Guillermo Bajo Laborda​\n",
    "* Laura Alejandra Moreno​\n",
    "* Arian Gharehmohammadzadehghashghaei​\n",
    "* Michele Pezza\n",
    "\n",
    "\n",
    "*Fundamentals of Data Science | Sapienza University of Rome*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CNN\n",
    "\n",
    "In this step, the image data has been loaded, and also a normaliation, resizing and augmentation process has been implemented.\n",
    "\n",
    "The key libraries used were TensorFlow for image processing, Pandas for handling the CSV files, and also os library. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', 'healthy', 'multiple_diseases', 'rust', 'scab'], dtype='object')\n",
      "  image_id  healthy  multiple_diseases  rust  scab\n",
      "0  Train_0        0                  0     0     1\n",
      "1  Train_1        0                  1     0     0\n",
      "2  Train_2        1                  0     0     0\n",
      "3  Train_3        0                  0     1     0\n",
      "4  Train_4        1                  0     0     0\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "data_dir = 'images/'  \n",
    "sample_submission_csv = 'sample_submission.csv'\n",
    "test_csv = 'test.csv'\n",
    "train_csv = 'train.csv' \n",
    "train_df = pd.read_csv(train_csv)\n",
    "print(train_df.columns)\n",
    "train_df.columns = train_df.columns.str.strip()\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the encoded labels into arrays\n",
    "def con_process_labels(df):\n",
    "    labels = df[['healthy', 'multiple_diseases', 'rust', 'scab']].values\n",
    "    return labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decode function to load and preprocess the image file\n",
    "\n",
    "def decode_image(filename, label=None, image_size=(512, 512)):\n",
    "    filepath = tf.strings.join([data_dir, filename])  \n",
    "    bits = tf.io.read_file(filepath)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    print(f\"decoded image shape: {image.shape}\")\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) \n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation to the images\n",
    "\n",
    "def data_augmentation(image, label=None):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Tensorflow dataset for testing\n",
    "\n",
    "def prepare_dataset(df, image_size=(512, 512), batch_size=32, augment=False, is_train=True):\n",
    "    file_paths = df['image_id'] + '.jpg'  \n",
    "    \n",
    "    if is_train:\n",
    "        labels = con_process_labels(df) \n",
    "        dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "        dataset = dataset.map(lambda x, y: decode_image(x, y, image_size))  \n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(file_paths)\n",
    "        dataset = dataset.map(lambda x: decode_image(x, label=None, image_size=image_size))\n",
    "    \n",
    "    if augment and is_train:\n",
    "        dataset = dataset.map(data_augmentation)  \n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)  \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create train dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m prepare_dataset(train_df, image_size\u001b[38;5;241m=\u001b[39m\u001b[43mimage_size\u001b[49m, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_size' is not defined"
     ]
    }
   ],
   "source": [
    "# Create train dataset\n",
    "train_dataset = prepare_dataset(train_df, image_size=image_size, augment=True, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded image shape: (512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(test_csv)\n",
    "test_df.columns = test_df.columns.str.strip()  # Clean the column names for test set\n",
    "test_dataset = prepare_dataset(test_df, image_size=(512, 512), augment=False, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Verification \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_batch, label_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage batch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_batch\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel batch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_batch\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#Verification \n",
    "\n",
    "for image_batch, label_batch in train_dataset.take(1):\n",
    "    print(f\"Image batch shape: {image_batch.shape}\")\n",
    "    print(f\"Label batch shape: {label_batch.shape}\")\n",
    "    \n",
    "    # Check the min and max values of the entire image batch\n",
    "    min_val = tf.reduce_min(image_batch).numpy()\n",
    "    max_val = tf.reduce_max(image_batch).numpy()\n",
    "    print(\"Image batch min and max values:\", min_val, max_val)\n",
    "    \n",
    "    # Check if any image has invalid values (NaN or Inf)\n",
    "    if tf.reduce_any(tf.math.is_nan(image_batch)):\n",
    "        print(\"Warning: There are NaN values in the image batch.\")\n",
    "    if tf.reduce_any(tf.math.is_inf(image_batch)):\n",
    "        print(\"Warning: There are Inf values in the image batch.\")\n",
    "\n",
    "    # Start plotting the first 9 images from the batch\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(9):  \n",
    "        plt.subplot(3, 3, i+1)\n",
    "        img = image_batch[i].numpy() \n",
    "        img_min = np.min(img)\n",
    "        img_max = np.max(img)\n",
    "        print(f\"Image {i} range: min={img_min}, max={img_max}\")\n",
    "        \n",
    "        # Check for NaN or Inf in individual image\n",
    "        if np.any(np.isnan(img)):\n",
    "            print(f\"Warning: Image {i} contains NaN values.\")\n",
    "        if np.any(np.isinf(img)):\n",
    "            print(f\"Warning: Image {i} contains Inf values.\")\n",
    "        \n",
    "        # Clip values to [0, 1] for normalization, then rescale to [0, 255]\n",
    "        img = np.clip(img, 0, 1) \n",
    "        img = (img * 255).astype(np.uint8) \n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Label: {np.argmax(label_batch[i].numpy())}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Softmax Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will focus on preprocessing image data and extracting additional features, such as color histograms, to enhance the model's performance. These features will be used alongside the images to train a convolutional neural network (CNN) model capable of classifying images into four categories: healthy, multiple_diseases, rust, and scab. We will then evaluate the model's performance using key metrics such as accuracy, confusion matrix, and F1-score. Ultimately, this approach will integrate both color histograms and images to achieve a more robust and accurate classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract histograms for R, G, B channels and vectorie them\n",
    "\n",
    "#This function extracts color histograms for the Red, Green, and Blue channels, \n",
    "#normalizes the values, and returns them as a combined vector\n",
    "def extract_color_histogram(image, bins=256):\n",
    "   \n",
    "    # Calculate histograms for each color channel (R, G, B)\n",
    "    r_hist = tf.histogram_fixed_width(image[..., 0], [0.0, 1.0], nbins=bins)\n",
    "    g_hist = tf.histogram_fixed_width(image[..., 1], [0.0, 1.0], nbins=bins)\n",
    "    b_hist = tf.histogram_fixed_width(image[..., 2], [0.0, 1.0], nbins=bins)\n",
    "    \n",
    "    # Normalize the histograms by dividing by the total number of pixels\n",
    "    total_pixels = tf.size(image[..., 0], out_type=tf.float32)  \n",
    "    r_hist = tf.cast(r_hist, tf.float32) / total_pixels\n",
    "    g_hist = tf.cast(g_hist, tf.float32) / total_pixels\n",
    "    b_hist = tf.cast(b_hist, tf.float32) / total_pixels\n",
    "    \n",
    "    # Concatenate the R, G, B histograms into a single vector\n",
    "    color_histogram = tf.concat([r_hist, g_hist, b_hist], axis=-1)\n",
    "\n",
    "    # Ensure values are within [0, 1]\n",
    "    color_histogram = tf.clip_by_value(color_histogram, 0.0, 1.0)\n",
    "\n",
    "    return color_histogram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare color histograms for a dataset (no labels)\n",
    "\n",
    "#This function processes all images in the dataframe by reading and \n",
    "#resizing them, then extracting the color histograms\n",
    "def prepare_color_histograms(df, image_size=(500, 500)):\n",
    "    def process_image(filename):\n",
    "        filepath = tf.strings.join([data_dir, filename])  \n",
    "        bits = tf.io.read_file(filepath)\n",
    "        image = tf.image.decode_jpeg(bits, channels=3)  # Decode the image\n",
    "        image = tf.image.resize(image, image_size)  # Resize the image\n",
    "        color_histogram = extract_color_histogram(image)  # Extract the color histogram\n",
    "        return color_histogram\n",
    "\n",
    "    file_paths = df['image_id'] + '.jpg'  # Get the file paths for images\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(file_paths)\n",
    "    dataset = dataset.map(process_image)  # Apply the process_image function to all file paths\n",
    "    histograms = [hist.numpy() for hist in dataset]  # Convert the results to numpy arrays\n",
    "    return histograms   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the one-hot encoded labels\n",
    "\n",
    "# This function converts the labels into one-hot encoded vectors\n",
    "def prepare_one_hot_labels(df):\n",
    "    labels = df[['healthy', 'multiple_diseases', 'rust', 'scab']].values\n",
    "    return tf.convert_to_tensor(labels, dtype=tf.float32)  # Convert to tensorflow tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the image dataset (for training)\n",
    "\n",
    "#This function prepares a dataset of images for training, decoding and resizing the images\n",
    "def prepare_image_dataset(df, image_size=(512, 512)):\n",
    "    def decode_image(filename, image_size=(512, 512)):\n",
    "        filepath = tf.strings.join([data_dir, filename])  \n",
    "        bits = tf.io.read_file(filepath)\n",
    "        image = tf.image.decode_jpeg(bits, channels=3)\n",
    "        image = tf.image.resize(image, image_size)  # Resize the image\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)  # Normalize image to [0, 1]\n",
    "        return image\n",
    "\n",
    "    file_paths = df['image_id'] + '.jpg'  # Get the file paths for images\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(file_paths)\n",
    "    dataset = dataset.map(lambda x: decode_image(x, image_size))  # Apply image decoding function\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine images and histograms into a single dataset\n",
    "\n",
    "# This function combines the image dataset and histogram dataset into a single dataset, \n",
    "# along with the labels for training.\n",
    "def combine_image_and_histogram_datasets(image_dataset, histograms_dataset, labels_dataset):\n",
    "    combined_dataset = tf.data.Dataset.zip((image_dataset, histograms_dataset, labels_dataset))\n",
    "    combined_dataset = combined_dataset.batch(32).prefetch(tf.data.AUTOTUNE)  # Batch and prefetch for better performance\n",
    "    return combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "\n",
    "# This function builds the CNN model, using the input shape of the images.\n",
    "# It consists of convolutional layers followed by dense layers for classification\n",
    "def build_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        # Convolutional layers for feature extraction\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),  # Flatten the output of the convolutional layers\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')  # Output layer for the 4 possible classes\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "#This function compiles and trains the model on the given dataset\n",
    "def train_model(train_dataset):\n",
    "    # Build the model\n",
    "    model = build_model(input_shape=(512, 512, 3))  # Input shape is (512, 512, 3) for images\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Compile the model\n",
    "    \n",
    "    # Train the model on the combined dataset (images + histograms)\n",
    "    history = model.fit(train_dataset, epochs=10)  # Train for 10 epochs\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "#This function evaluates the trained model on the test dataset\n",
    "def evaluate_model(model, test_dataset):\n",
    "    test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "    # Additional metrics: Confusion matrix and F1-score\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "    # Get predictions and true labels\n",
    "    y_pred = model.predict(test_dataset)\n",
    "    y_true = [labels.numpy() for _, labels in test_dataset]\n",
    "\n",
    "    # Convert predictions and labels to single values (from one-hot encoding)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(np.array(y_true), axis=1)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # F1-score\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to MapDataset:11 transformation with iterator: Iterator::Root::ParallelMapV2: NewRandomAccessFile failed to Create/Open: images/Train_0.jpg : El sistema no puede encontrar el archivo especificado.\r\n; No such file or directory\n\t [[{{node ReadFile}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Prepare train dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_histograms \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_color_histograms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m prepare_one_hot_labels(train_df)\n\u001b[0;32m      4\u001b[0m train_histograms_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(train_histograms)\n",
      "Cell \u001b[1;32mIn[28], line 17\u001b[0m, in \u001b[0;36mprepare_color_histograms\u001b[1;34m(df, image_size)\u001b[0m\n\u001b[0;32m     14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(process_image)  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     15\u001b[0m histograms \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 17\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhist\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistograms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histograms\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3113\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3111\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3113\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3115\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to MapDataset:11 transformation with iterator: Iterator::Root::ParallelMapV2: NewRandomAccessFile failed to Create/Open: images/Train_0.jpg : El sistema no puede encontrar el archivo especificado.\r\n; No such file or directory\n\t [[{{node ReadFile}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "# Prepare train dataset\n",
    "#train_histograms = prepare_color_histograms(train_df)\n",
    "#train_labels = prepare_one_hot_labels(train_df)\n",
    "#train_histograms_dataset = tf.data.Dataset.from_tensor_slices(train_histograms)\n",
    "#train_labels_dataset = tf.data.Dataset.from_tensor_slices(train_labels)\n",
    "#train_dataset = tf.data.Dataset.zip((train_histograms_dataset, train_labels_dataset))\n",
    "#train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Prepare test dataset (no labelS, only histograms)\n",
    "#test_df = pd.read_csv(test_csv)\n",
    "#test_df.columns = test_df.columns.str.strip()\n",
    "#test_histograms = prepare_color_histograms(test_df)\n",
    "#test_histograms_dataset = tf.data.Dataset.from_tensor_slices(test_histograms)\n",
    "#test_dataset = test_histograms_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "#for histograms, labels in train_dataset.take(1):\n",
    "#    print(\"Histograms:\", histograms.numpy()[:5])\n",
    "#    print(\"Labels:\", labels.numpy()[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
